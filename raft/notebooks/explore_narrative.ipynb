{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vohun\\anaconda3\\envs\\py10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Resolving data files: 100%|██████████| 24/24 [00:02<00:00, 11.41it/s]\n",
      "Resolving data files: 100%|██████████| 24/24 [00:02<00:00, 11.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'question', 'answers'],\n",
       "    num_rows: 10557\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "dataset_id = \"deepmind/narrativeqa\"\n",
    "\n",
    "dataset = load_dataset(dataset_id, split=\"test\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answers', 'context', 'context_id'],\n",
      "    num_rows: 10557\n",
      "})\n",
      "{'question': 'Who is Mark Hunter?', 'answers': ['He is a high school student in Phoenix.', 'A loner and outsider student with a radio station.'], 'context': ' Mark Hunter (Slater), a high school student in a sleepy suburb of Phoenix, Arizona, starts an FM pirate radio station that broadcasts from the basement of his parents\\' house. Mark is a loner, an outsider, whose only outlet for his teenage angst and aggression is his unauthorized radio station. His pirate station\\'s theme song is \"Everybody Knows\" by Leonard Cohen and there are glimpses of cassettes by such alternative musicians as The Jesus and Mary Chain, Camper Van Beethoven, Primal Scream, Soundgarden, Ice-T, Bad Brains, Concrete Blonde, Henry Rollins, and The Pixies. By day, Mark is seen as a loner, hardly talking to anyone around him; by night, he expresses his outsider views about what is wrong with American society. When he speaks his mind about what is going on at his school and in the community, more and more of his fellow students tune in to hear his show.\\nNobody knows the true identity of \"Hard Harry\" or \"Happy Harry Hard-on,\" as Mark refers to himself, until Nora Diniro (Mathis), a fellow student, tracks him down and confronts him the day after a student named Malcolm commits suicide after Harry attempts to reason with him. The radio show becomes increasingly popular and influential after Harry confronts the suicide head-on, exhorting his listeners to do something about their problems instead of surrendering to them through suicideâ\\x80\\x94at the crescendo of his yelled speech, an overachieving student named Paige Woodward (who has been a constant listener) jams her various medals and accolades into a microwave and turns it on. She then sits, watching the awards cook until the microwave explodes, injuring her. While this is happening, other students act out in cathartic release.\\nEventually, the radio show causes so much trouble in the community that the FCC is called in to investigate. During the fracas, it is revealed that the school\\'s principal (Annie Ross) has been expelling \"problem students,\" namely, students with below-average standardized test scores, in an effort to boost the district\\'s test scores while still keeping their names on the rolls (a criminal offense) in order to retain government funding.\\nRealizing he has started something huge, Mark decides it is up to him to end it. He dismantles his radio station and attaches it to his mother\\'s old jeep, creating a mobile transmitter so his position can\\'t be triangulated. Pursued by the police and the FCC, Nora drives the jeep around while Mark broadcasts. The harmonizer he uses to disguise his voice breaks, and with no time left to fix it, Mark decides to broadcast his final message as himself. They finally drive up to the crowd of protesting students, and Mark tells them that the world belongs to them and that they should make their own future. The police step in and arrest Mark and Nora. As they are taken away, Mark reminds the students to \"talk hard.\" As the film ends, the voices of other students (and even one of the teachers) speak as intros for their own independent stations, which can be heard broadcasting across the country.', 'context_id': '0025577043f5090cd603c6aea60f26e236195594'}\n"
     ]
    }
   ],
   "source": [
    "def get_context(ex):\n",
    "  ctx = ex[\"document\"][\"summary\"][\"text\"]\n",
    "  ctx_id = ex[\"document\"][\"id\"]\n",
    "  question = ex[\"question\"][\"text\"]\n",
    "  answers = [each[\"text\"] for each in ex[\"answers\"]]\n",
    "  return dict(context=ctx, context_id=ctx_id, question=question, answers=answers)\n",
    "dataset = dataset.map(get_context)\n",
    "dataset = dataset.remove_columns([\"document\"])\n",
    "dataset[1]\n",
    "print(dataset)\n",
    "col = dataset[0]\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305 50\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "unique_contexts = Counter(dataset[\"context\"])\n",
    "count = 0\n",
    "raft_train_ctx = []\n",
    "raft_test_ctx = []\n",
    "for k, v in unique_contexts.items():\n",
    "  if v > 5 and count < 50:\n",
    "    count += 1\n",
    "    raft_train_ctx.append(k)\n",
    "  else:\n",
    "    raft_test_ctx.append(k)\n",
    "\n",
    "print(len(raft_test_ctx), len(raft_train_ctx))\n",
    "\n",
    "#raft_train_ctx = unique_contexts[:100]\n",
    "#raft_test_ctx = unique_contexts[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 10557/10557 [00:00<00:00, 61128.98 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answers', 'context', 'context_id'],\n",
       "    num_rows: 9059\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = dataset.filter(lambda x: x[\"context\"] in raft_test_ctx)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answers', 'context_id'],\n",
       "    num_rows: 305\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "test_dataset_unique_ctx = test_dataset.to_pandas()\n",
    "test_dataset_unique_ctx = test_dataset_unique_ctx.groupby(\"context\").first().reset_index()\n",
    "test_dataset_unique_ctx = Dataset.from_pandas(test_dataset_unique_ctx)\n",
    "test_dataset_unique_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 36.11ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 199.94ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "c:\\Users\\vohun\\anaconda3\\envs\\py10\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vohun\\.cache\\huggingface\\hub\\datasets--phatvo--narrativeqa-test-raft. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/phatvo/narrativeqa-test-raft/commit/b6e03590a6b21d495664c9217ecd0d9e8b18b04f', commit_message='Upload dataset', commit_description='', oid='b6e03590a6b21d495664c9217ecd0d9e8b18b04f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset for evaluation raft\n",
    "uploaded_dataset_id = \"phatvo/narrativeqa-test-raft\"\n",
    "test_dataset.push_to_hub(uploaded_dataset_id, split=\"test\", private=True)\n",
    "test_dataset_unique_ctx.push_to_hub(uploaded_dataset_id, split=\"test_unique_ctx\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_context_to_file(data:list, filepath):\n",
    "  with open(filepath, \"w\") as f:\n",
    "    _data = [each.replace(\"\\n\", \"\") for each in data]\n",
    "    f.write(\"\\n\".join(_data) + \"\\n\")\n",
    "\n",
    "save_context_to_file(raft_train_ctx, \"../data/context_for_generate_narrativeqa.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "python3 raft.py \\\n",
    "    --datapath \"data/context_for_generate_narrativeqa.txt\" \\\n",
    "    --output \"tmp/narrativeqa-test-50-raft2\" \\\n",
    "    --distractors 3 \\\n",
    "    --doctype txt \\\n",
    "    --chunk_size 512 \\\n",
    "    --questions 1 \\\n",
    "    --openai_key $OPENAI_KEY \\\n",
    "    --completion_model gpt-4o \\\n",
    "    --splitter breakline --p 0.9\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $env:OPENAI_KEY="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vohun\\anaconda3\\envs\\py10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 50 examples [00:00, 2731.73 examples/s]\n",
      "Map: 100%|██████████| 50/50 [00:00<00:00, 1438.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'type', 'question', 'context', 'oracle_context', 'cot_answer', 'instruction', 'text'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"json\", data_files=\"../tmp/narrativeqa-test-50-raft2.jsonl\", )\n",
    "ds = ds.map(lambda x: {\"text\": f\"{x['instruction']}\\nCoT Answer: {x['cot_answer']}\"})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 62.39ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/phatvo/narrativeqa-raft-50-p0.9/commit/19e7a364805766846a5783c5ae2ec55ef5b09077', commit_message='Upload dataset', commit_description='', oid='19e7a364805766846a5783c5ae2ec55ef5b09077', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.push_to_hub(\"phatvo/narrativeqa-raft-50-p0.9\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
